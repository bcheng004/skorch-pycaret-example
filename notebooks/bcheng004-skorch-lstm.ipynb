{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "import warnings\r\n",
    "warnings.simplefilter(action='ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTM Skorch example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.datasets import make_regression\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from skorch import NeuralNetRegressor\r\n",
    "import torch.nn as nn\r\n",
    "import torch\r\n",
    "from icecream import ic\r\n",
    "\r\n",
    "X_regr, y_regr = make_regression(\r\n",
    "    1000,\r\n",
    "    20,\r\n",
    "    n_informative=10,\r\n",
    "    random_state=0\r\n",
    ")\r\n",
    "X_regr = X_regr.astype(np.float32)\r\n",
    "y_regr = y_regr.astype(np.float32)/100\r\n",
    "y_regr = y_regr.reshape(-1,1)\r\n",
    "ni, no, nh, nlayers = 20, 1, 10, 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "class LSTM(nn.Module):\r\n",
    "    def __init__(self,ni=6,no=3,nh=10,nlayers=1):\r\n",
    "        super(LSTM,self).__init__()\r\n",
    "        self.ni = ni\r\n",
    "        self.no = no\r\n",
    "        self.nh = nh\r\n",
    "        self.nlayers = nlayers\r\n",
    "        self.lstms = nn.ModuleList(\r\n",
    "            [nn.LSTMCell(self.ni,self.nh)]+[nn.LSTMCell(self.nh,self.nh) for i in range(nlayers-1)]\r\n",
    "        )\r\n",
    "        self.out = nn.Linear(self.nh,self.no)\r\n",
    "        self.do = nn.Dropout(p=0.2)\r\n",
    "        self.activation_function = nn.Tanh()\r\n",
    "        self.dtype = torch.float\r\n",
    "    def forward(self,x,h0=None,train=False):\r\n",
    "        hs = x # initiate hidden state\r\n",
    "        if h0 is None:\r\n",
    "            h = torch.zeros(hs.shape[0],self.nh,device=x.device)\r\n",
    "            c = torch.zeros(hs.shape[0],self.nh,device=x.device)\r\n",
    "        else:\r\n",
    "            (h,c) = h0\r\n",
    "        # LSTM cells\r\n",
    "        for i in range(self.nlayers):\r\n",
    "            h, c = self.lstms[i](hs, (h,c))\r\n",
    "            if train:\r\n",
    "                hs = self.do(h)\r\n",
    "            else:\r\n",
    "                hs = h\r\n",
    "        y = self.out(hs)\r\n",
    "        return y, (h,c)\r\n",
    "\r\n",
    "class ContextlessMSE(nn.MSELoss):\r\n",
    "    def forward(self,y_pred,y_true):\r\n",
    "        y, (h,c) = y_pred # extract prediction and context information\r\n",
    "        return super().forward(y,y_true)\r\n",
    "\r\n",
    "lstm_regressor = NeuralNetRegressor(\r\n",
    "    module=LSTM, \r\n",
    "    module__ni=ni,\r\n",
    "    module__no=no,\r\n",
    "    module__nh=nh,\r\n",
    "    module__nlayers=nlayers,\r\n",
    "    max_epochs=20,\r\n",
    "    lr=0.1,\r\n",
    "    criterion=ContextlessMSE\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "lstm_regressor_pipeline = Pipeline([('lstm',lstm_regressor)])\r\n",
    "lstm_regressor_pipeline.fit(X_regr,y_regr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.7202\u001b[0m        \u001b[32m4.0712\u001b[0m  0.0222\n",
      "      2        \u001b[36m4.6817\u001b[0m        \u001b[32m4.0438\u001b[0m  0.0283\n",
      "      3        \u001b[36m4.6543\u001b[0m        \u001b[32m4.0213\u001b[0m  0.0255\n",
      "      4        \u001b[36m4.6274\u001b[0m        \u001b[32m3.9967\u001b[0m  0.0322\n",
      "      5        \u001b[36m4.5950\u001b[0m        \u001b[32m3.9648\u001b[0m  0.0206\n",
      "      6        \u001b[36m4.5500\u001b[0m        \u001b[32m3.9174\u001b[0m  0.0286\n",
      "      7        \u001b[36m4.4792\u001b[0m        \u001b[32m3.8385\u001b[0m  0.0384\n",
      "      8        \u001b[36m4.3555\u001b[0m        \u001b[32m3.6909\u001b[0m  0.0322\n",
      "      9        \u001b[36m4.1121\u001b[0m        \u001b[32m3.3738\u001b[0m  0.0350\n",
      "     10        \u001b[36m3.5666\u001b[0m        \u001b[32m2.6097\u001b[0m  0.0240\n",
      "     11        \u001b[36m2.3671\u001b[0m        \u001b[32m1.2702\u001b[0m  0.0303\n",
      "     12        \u001b[36m1.0404\u001b[0m        \u001b[32m0.6253\u001b[0m  0.0251\n",
      "     13        \u001b[36m0.6314\u001b[0m        \u001b[32m0.5236\u001b[0m  0.0295\n",
      "     14        \u001b[36m0.5443\u001b[0m        \u001b[32m0.4820\u001b[0m  0.0309\n",
      "     15        \u001b[36m0.4885\u001b[0m        \u001b[32m0.4523\u001b[0m  0.0461\n",
      "     16        \u001b[36m0.4408\u001b[0m        \u001b[32m0.4340\u001b[0m  0.0302\n",
      "     17        \u001b[36m0.4015\u001b[0m        \u001b[32m0.4155\u001b[0m  0.0285\n",
      "     18        \u001b[36m0.3717\u001b[0m        \u001b[32m0.3600\u001b[0m  0.0285\n",
      "     19        \u001b[36m0.3291\u001b[0m        \u001b[32m0.3247\u001b[0m  0.0271\n",
      "     20        \u001b[36m0.3039\u001b[0m        \u001b[32m0.2730\u001b[0m  0.0320\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('lstm',\n",
       "                 <class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=LSTM(\n",
       "    (lstms): ModuleList(\n",
       "      (0): LSTMCell(20, 10)\n",
       "      (1): LSTMCell(10, 10)\n",
       "      (2): LSTMCell(10, 10)\n",
       "    )\n",
       "    (out): Linear(in_features=10, out_features=1, bias=True)\n",
       "    (do): Dropout(p=0.2, inplace=False)\n",
       "    (activation_function): Tanh()\n",
       "  ),\n",
       "))])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# lstm_regressor_pipeline.named_steps['lstm'].get_params()\r\n",
    "y_pred = lstm_regressor_pipeline.predict(X_regr[:5])\r\n",
    "ic(y_pred);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| y_pred: array([[ 0.44321513],\n",
      "                   [-1.9767034 ],\n",
      "                   [-0.13864079],\n",
      "                   [-0.6392553 ],\n",
      "                   [-0.70358443]], dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "64d303618c8ee9f1cee103d362ed2586b5f50e4b11555251f761d52c2b006ae5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}